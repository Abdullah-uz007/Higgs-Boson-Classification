def build_deeper_model(input_shape, optimizer_name, learning_rate):
  ##  Defines a deeper model with a different optimizer (AdamW)
    model = models.Sequential([
        layers.Input(shape=(input_shape,)), 

        layers.Dense(256, kernel_regularizer=l2(0.001)),
        layers.BatchNormalization(),
        layers.ReLU(),
        layers.Dropout(0.4),

        layers.Dense(128, kernel_regularizer=l2(0.001)),
        layers.BatchNormalization(),
        layers.ReLU(),
        layers.Dropout(0.4),

        layers.Dense(64, kernel_regularizer=l2(0.001)),
        layers.BatchNormalization(),
        layers.ReLU(),
        layers.Dropout(0.3),

        layers.Dense(1, activation='sigmoid')
    ])

    # Use a different optimizer (AdamW)
    optimizer = optimizers.AdamW(learning_rate=learning_rate, weight_decay=1e-5)


    model.compile(
        optimizer=optimizer,
        loss='binary_crossentropy',
        metrics=['accuracy']
    )
    return model

# Build and Train Model 2 (Using a different optimizer and a deeper network)
DEEPER_LEARNING_RATE = 0.001
dl_model_deeper = build_deeper_model(INPUT_SHAPE, 'AdamW', DEEPER_LEARNING_RATE)
print(" Training Deep Learning Deeper Model (AdamW) ")
history_deeper = dl_model_deeper.fit(
    X_train_scaled, y_train,
    epochs=50,
    batch_size=BATCH_SIZE,
    validation_data=(X_val_scaled, y_val),
    callbacks=[early_stopping, reduce_lr],
    verbose=1 # Set to 1 to see progress
)

# Select the better-performing model for final evaluation
best_dl_model = dl_model_baseline



# Predict probabilities on the test set
y_pred_proba_dl = best_dl_model.predict(X_test_scaled).flatten()
# Convert probabilities to binary predictions (0 or 1)
y_pred_dl = (y_pred_proba_dl > 0.5).astype(int)

# 1. Report performance metrics
acc_dl = accuracy_score(y_test, y_pred_dl)
prec_dl = precision_score(y_test, y_pred_dl)
rec_dl = recall_score(y_test, y_pred_dl)
f1_dl = f1_score(y_test, y_pred_dl)
roc_auc_dl = roc_auc_score(y_test, y_pred_proba_dl)

print("deep learning model Metrics (Test Set) ")
print(f"Accuracy : {acc_dl:.4f}")
print(f"Precision: {prec_dl:.4f}")
print(f"Recall   : {rec_dl:.4f}")
print(f"F1 Score : {f1_dl:.4f}")
print(f"ROC AUC  : {roc_auc_dl:.4f}")

# 2. Plot training and validation accuracy/loss curves
fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))

# Loss Plot
ax1.plot(history_final.history['loss'], label='Train Loss')
ax1.plot(history_final.history['val_loss'], label='Validation Loss')
ax1.set_title('Training and Validation Loss')
ax1.set_xlabel('Epoch')
ax1.set_ylabel('Loss (Binary Crossentropy)')
ax1.legend()
ax1.grid(True)

# Accuracy Plot
ax2.plot(history_final.history['accuracy'], label='Train Accuracy')
ax2.plot(history_final.history['val_accuracy'], label='Validation Accuracy')
ax2.set_title('Training and Validation Accuracy')
ax2.set_xlabel('Epoch')
ax2.set_ylabel('Accuracy')
ax2.legend()
ax2.grid(True)
plt.show()

# 3. Confusion matrix and ROC-AUC curve

# Confusion Matrix
cm_dl = confusion_matrix(y_test, y_pred_dl)
plt.figure(figsize=(5,4))
sns.heatmap(cm_dl, annot=True, fmt='d', cmap='Blues')
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.title('Confusion Matrix - Deep Learning (Test Data)')
plt.show()

# ROC Curve
fpr_dl, tpr_dl, _ = roc_curve(y_test, y_pred_proba_dl)
plt.figure(figsize=(6,5))
plt.plot(fpr_dl, tpr_dl, label=f'ROC Curve (AUC = {roc_auc_dl:.4f})')
plt.plot([0,1], [0,1], 'k--', label='Random Guess (AUC = 0.5)')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC-AUC Curve - Deep Learning')
plt.legend(loc='lower right')
plt.grid(True)
plt.show()




history_final = history_baseline
