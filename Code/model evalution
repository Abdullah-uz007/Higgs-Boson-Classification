def plot_history(history):
    plt.figure(figsize=(12,5))

    # Loss curve
    plt.subplot(1,2,1)
    plt.plot(history.history['loss'], label='Train Loss')
    plt.plot(history.history['val_loss'], label='Val Loss')
    plt.title('Loss Curve')
    plt.xlabel('Epoch')
    plt.legend()

    # Accuracy curve
    plt.subplot(1,2,2)
    plt.plot(history.history['accuracy'], label='Train Acc')
    plt.plot(history.history['val_accuracy'], label='Val Acc')
    plt.title('Accuracy Curve')
    plt.xlabel('Epoch')
    plt.legend()

    plt.show()

plot_history(history_baseline)



# Generate predictions and probabilities for the test set using the deep learning model
y_pred_proba_dl = dl_model_baseline.predict(X_test_scaled)
y_pred_dl = (y_pred_proba_dl > 0.5).astype(int)





acc_dl = accuracy_score(y_test, y_pred_dl)
prec_dl = precision_score(y_test, y_pred_dl)
rec_dl = recall_score(y_test, y_pred_dl)
f1_dl = f1_score(y_test, y_pred_dl)
roc_auc_dl = roc_auc_score(y_test, y_pred_proba_dl)

print("Deep Learning Model Metrics (Test Set) ")
print(f"Accuracy : {acc_dl:.4f}")
print(f"Precision: {prec_dl:.4f}")
print(f"Recall   : {rec_dl:.4f}")
print(f"F1-Score : {f1_dl:.4f}")
print(f"ROC AUC  : {roc_auc_dl:.4f}")


# Confusion matrix
cm = confusion_matrix(y_test, y_pred_dl)
plt.figure(figsize=(5,4))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.title("Confusion Matrix – Neural Network")
plt.show()

# ROC curve
fpr, tpr, _ = roc_curve(y_test, y_pred_proba_dl)
roc_auc = auc(fpr, tpr)

plt.figure(figsize=(6,5))
plt.plot(fpr, tpr, label=f"AUC = {roc_auc:.4f}")
plt.plot([0,1],[0,1],'--',color='gray')
plt.xlabel("False Positive Rate")
plt.ylabel("True Positive Rate")
plt.title("ROC Curve – Neural Network")
plt.legend()
plt.show()




